services:
  mcp-textpseudomizer:
    build:
      context: .
      dockerfile: Dockerfile
      args:
        TORCH_INDEX_URL: "https://download.pytorch.org/whl/cpu"
    container_name: mcp-textpseudomizer
    ports:
      - "3000:3000"
    environment:
      - LOG_LEVEL=INFO
      - MODEL_CACHE_DIR=/app/models
      - TORCH_DEVICE=cpu
      - MIN_CONFIDENCE_THRESHOLD=0.5
      - MAX_TEXT_LENGTH=10000
      - BATCH_SIZE=10
      - DEFAULT_LANGUAGE=auto
      - GRACEFUL_DEGRADATION=true
      - TIMEOUT_SECONDS=30
      - MCP_TRANSPORT=tcp
      - MCP_PORT=3000
    volumes:
      # Persistent model cache
      - model-cache:/app/models
      # Persistent logs
      - ./logs:/app/logs
      # Optional: Mount custom .env file
      - ./.env:/app/.env:ro
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "python", "-c", "
        import sys; sys.path.append('/app');
        from src.pseudonymizer import TextPseudonymizer;
        p = TextPseudonymizer();
        r = p.detect_language('test');
        assert r.language in ['en', 'de']
      "]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 60s
    deploy:
      resources:
        limits:
          memory: 4G
          cpus: '2.0'
        reservations:
          memory: 2G
          cpus: '1.0'

volumes:
  model-cache:
    driver: local